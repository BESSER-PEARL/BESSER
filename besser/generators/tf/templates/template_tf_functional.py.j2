{%- import "setup_nn_components.py.j2" as nn_components -%}
{%- set si = namespace(sequential_imported=False) -%}
import tensorflow as tf
from tensorflow.keras import layers
{% for module_name, module_details in modules_details.items() -%}
{% if module_name.endswith("nn") and si.sequential_imported == False %}from tensorflow.keras.models import Sequential {%- set si.sequential_imported = True -%} {% endif %}{% endfor %}
{% if model.configuration and model.configuration.weight_decay != 0 %}from besser.generators.tf.utils import loss_with_weight_decay {% endif %} 
{%- if model.train_data is not none %}
{% if model.train_data.task_type != "regression" %}from sklearn.metrics import classification_report 
{%- else -%} from sklearn.metrics import mean_absolute_error {%- endif %} 
{% if model.train_data.input_format == "csv" %}import pandas as pd {%- endif %}
{%- endif %}
{%- for module_name, module_details in modules_details.items() -%}
{%- if module_name.endswith("layer") %}{% if module_details[0].split("=")[1].strip().startswith("tfa") %}import tensorflow_addons as tfa  {% endif %}{% endif %}{% endfor %}
{% if model.train_data.input_format == "images" %}from besser.generators.tf.utils import compute_mean_std{%- endif %}

# Define the network architecture
class NeuralNetwork(tf.keras.Model):
    def __init__(self):
        super().__init__()
        {%- for module_name, module_details in modules_details.items() -%}
        {%- if module_name.endswith("nn") %}

        self.{{ module_name.split('_')[0] }} = Sequential([
            {%- for subnn_key, subnn_value in module_details.items() %}
            {%- if subnn_key != "in_out_variable" %}
            {%- if "layers.ZeroPadding" in subnn_value[0] %}
            {{ subnn_value[0].split("#")[0].split('=', 1)[1].strip() }},
            {{ subnn_value[0].split("#")[1].split('=', 1)[1].strip() }},
            {%- else %}
            {{ subnn_value[0].split('=', 1)[1].strip() }},
            {%- endif -%}
            {%- endif -%}
            {%- endfor %}
        ])

        {%- elif module_name.endswith("layer") %}
        {%- if "layers.ZeroPadding" in module_details[0] %}
        {{ module_details[0].split("#")[0].strip() }}
        {{ module_details[0].split("#")[1].strip() }}
        {%- else %}
        {{ module_details[0] }}
        {%- endif -%}
        {%- endif -%}
        {%- endfor %}
    {% set return_variable =  namespace(value="") %}
    def call(self, x):
    {%- for module_name, module_details in modules_details.items() -%}
    {%- if module_name.endswith("op") %}
        {{ module_details[1] }} = {{ module_details[0] }}
    {%- elif module_name.endswith("nn") %} 
        {{ module_details["in_out_variable"] }} = self.{{ module_name.rsplit('_', 2)[0] }}({{ module_details["in_out_variable"] }})
    {%- else %}
        {%- if "layers.ZeroPadding" in module_details[0] %}
        {{ module_details[1] }} = self.{{ module_name.rsplit('_', 1)[0] }}_pad({{ module_details[2] }})
        {{ module_details[1] }} = self.{{ module_name.rsplit('_', 1)[0] }}({{ module_details[2] }})
        {%- elif module_details[-1].__class__.mro()[1].__name__ == "RNN" %}
            {%- if module_details[-1].return_type == "hidden" %}
                {%- if module_details[-1].__class__.__name__ == "LSTMLayer" and module_details[-1].bidirectional %}
        _, forward_h_n, _, backward_h_n, _ = self.{{ module_name.rsplit('_', 1)[0] }}({{ module_details[2] }})
                {%- elif module_details[-1].__class__.__name__ == "LSTMLayer" %}
        _, {{ module_details[1] }}, _ = self.{{ module_name.rsplit('_', 1)[0] }}({{ module_details[2] }})
                {%- elif module_details[-1].__class__.__name__ != "LSTMLayer" and module_details[-1].bidirectional %}
        _, forward_h_n, backward_h_n = self.{{ module_name.rsplit('_', 1)[0] }}({{ module_details[2] }})
                {%- else %}
        _, {{ module_details[1] }} = self.{{ module_name.rsplit('_', 1)[0] }}({{ module_details[2] }})
                {%- endif -%}
                {%- if module_details[-1].bidirectional %}
        {{ module_details[1] }} = tf.concat([forward_h_n, backward_h_n], axis=-1)
                {%- endif -%}
            {%- else %}
        {{ module_details[1] }} = self.{{ module_name.rsplit('_', 1)[0] }}({{ module_details[2] }})
            {%- endif -%}
        {%- else %}
        {{ module_details[1] }} = self.{{ module_name.rsplit('_', 1)[0] }}({{ module_details[2] }})
    {%- endif -%}
    {%- endif -%}
    {%- if module_name.endswith("nn") %}
    {%- set return_variable.value =  module_details["in_out_variable"] %}
    {%- else %} 
    {%- set return_variable.value =  module_details[1] %}
    {%- endif -%}
    {%- endfor %}
        {%- if "," in return_variable.value %}
        return {{ return_variable.value.split(",")[0].strip() if return_variable.value.split(",")[0].strip()!="_" else return_variable.value.split(",")[1].strip()}}
        {%- else %}
        return {{ return_variable.value }}
        {%- endif %}

{%- set last_module = modules_details.items() | last -%}
{%- if last_module[0].endswith("layer") -%}
{%- if last_module[1][-1].actv_func is none -%}
{%- set from_logits =  namespace(flag=True) -%}
{%- else -%}
{%- set from_logits =  namespace(flag=False) -%}
{%- endif -%}
{%- elif last_module[0].endswith("nn") -%}
{%- set last_layer_sub_nn = last_module[1].items() | last -%}
{%- if last_layer_sub_nn[1][-1].actv_func is none -%}
{%- set from_logits =  namespace(flag=True) -%}
{%- else -%}
{%- set from_logits =  namespace(flag=False) -%}
{%- endif %}
{%- endif %}

{% if model.train_data is not none %}
# Dataset preparation
{{ nn_components.prepare_data(model.train_data, model.test_data, model.configuration) }}


# Define the network, loss function, and optimiser
{{ model.name }} = NeuralNetwork()
criterion = {{ nn_components.get_loss_function(model.configuration, from_logits) }}
optimizer = {{ nn_components.get_optimiser(model) }}

# Train the neural network
{{ nn_components.train_model(model, model.train_data.task_type) }}

# Evaluate the neural network
{{ nn_components.evaluate_model(model, model.train_data.task_type) }}
{%- endif -%}